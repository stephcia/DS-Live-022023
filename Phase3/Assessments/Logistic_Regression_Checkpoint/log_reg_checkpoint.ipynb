{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f17628a8eca2cbc0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Logistic Regression Checkpoint\n",
    "\n",
    "This checkpoint is designed to test your understanding of the content from the Logistic Regression Cumulative Lab.\n",
    "\n",
    "Specifically, this will cover:\n",
    "\n",
    "* Calculating and interpreting classification metrics, particularly in the context of class imbalance\n",
    "* Performing an end-to-end ML process with logistic regression\n",
    "* Using NumPy and not pandas in a modeling context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f2bd8816c42b2fb1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Your Task: Use Logistic Regression on the Wisconsin Breast Cancer Dataset\n",
    "\n",
    "### Data Understanding\n",
    "\n",
    "Here we will use the Wisconsin Breast Cancer dataset, which is available through scikit-learn ([documentation here](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset)).  The goal is to predict whether a breast mass is benign or malignant based on attributes of cell nuclei in a tissue sample. Deeper understanding of the specific attributes is not required for this task.\n",
    "\n",
    "In the cell below, we load this dataset, perform a train-test split, and scale the data for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5acfbd990f38a8e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('breast_cancer.csv')\n",
    "# Seperate features from target\n",
    "X, y = df.iloc[:,:-1].to_numpy(), df.iloc[:,-1].to_numpy()\n",
    "# Perform train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "# Scale data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-900fc5185c49d611",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 1. Baseline Metrics\n",
    "\n",
    "Before we actually perform any modeling, let's determine what metrics we would expect to get with a \"dummy\" model that always predicts the positive class.\n",
    "\n",
    "For this assessment we'll define \"negative\" as a 0 (benign) and \"positive\" as a 1 (malignant).\n",
    "\n",
    "We will focus on the test data, since this is what we will use to evaluate our actual model as well.\n",
    "\n",
    "The code below shows an array containing the number of records in the test dataset with class 0 (benign) and class 1 (malignant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3749265b38571fac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a235418dd6df809c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "In other words, a model that always predicts the positive class, will predict a 1 for every observation. Given the imbalance of the target seen above, (The balance is similar in the training data as well), we will calculate different classification metrics to evaluate the model's performance for both positive and negative labels.\n",
    "\n",
    "The confusion matrix looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f5e5c157e227ff7e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Run this cell without changes\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "plot_confusion_matrix(DummyClassifier(strategy='constant', constant=1).fit(X_train, y_train), X_test, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6cc083aefe185bc9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "For each of the following questions, assume that a \"baseline\" metric means the metric we would find if our model always chose class 1.\n",
    "\n",
    "You can just use the numbers 89 and 54 in your answer; you don't need to use `y_test` directly.\n",
    "\n",
    "#### What is the baseline accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-4fc8ecbde3cefea5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1.1\n",
    "# Replace None with appropriate code\n",
    "baseline_accuracy = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_accuracy should be a number between 0 and 1\n",
    "assert 0.0 <= baseline_accuracy and baseline_accuracy <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ce29090a1e7a50a3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### What is the baseline recall?\n",
    "\n",
    "As a reminder, a \"negative\" prediction is represented as 0 (benign) and a \"positive\" prediction as 1 (malignant). So all baseline predictions will be either \"true positives\" (actually 1, predicted 1) or \"false positives\" (actually 0, predicted 1) and there will not be any \"true negatives\" or \"false negatives\" because this model always chooses 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bd2963c096bc719d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1.2\n",
    "# Replace None with appropriate code\n",
    "baseline_recall = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_recall should be a number between 0 and 1\n",
    "assert 0.0 <= baseline_recall and baseline_recall <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-dba77045ab3d5734",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### What is the baseline precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-ad278d44219e8d59",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1.3\n",
    "# Replace None with appropriate code\n",
    "baseline_precision = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_precision should be a number between 0 and 1\n",
    "assert 0.0 <= baseline_precision and baseline_precision <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-09a829b393083712",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### What is the baseline f1-score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2df160d3ab75209",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step1.4\n",
    "# Replace None with appropriate code\n",
    "baseline_f1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline_f1 should be a number between 0 and 1\n",
    "assert 0.0 <= baseline_f1 and baseline_f1 <= 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-594415dfc9fb22d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2. Instantiate and Fit a `LogisticRegression` Model\n",
    "\n",
    "Use the `LogisticRegression` model from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)). Specify a `random_state` of 42 but otherwise use default hyperparameters.\n",
    "\n",
    "Because logistic regression applies regularization by default, make sure you use the scaled training data to fit the model.\n",
    "\n",
    "Call this model `model`.\n",
    "\n",
    "We have also included code to display the confusion matrix on the training data; if the confusion matrix doesn't render, that indicates that something is incorrect about your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b2952b81667870c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step2\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Import the relevant class\n",
    "None\n",
    "\n",
    "# Instantiate the model\n",
    "model = None\n",
    "\n",
    "# Fit the model on the scaled data\n",
    "None\n",
    "\n",
    "plot_confusion_matrix(model, X_train_scaled, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model should be a LogisticRegression\n",
    "assert type(model) == LogisticRegression\n",
    "\n",
    "# model should be fitted\n",
    "assert type(model.coef_) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Use Cross-Validation to Evaluate the Fitted Model\n",
    "\n",
    "Use `cross_val_score` from scikit-learn ([documentation here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html)) to evaluate the expected accuracy of the fitted model, make sure to still use the scaled training data.\n",
    "\n",
    "Use a `cv` of 3 and assign the result to `cv_scores`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b52c61d710a43d8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step3\n",
    "# Replace None with appropriate code\n",
    "\n",
    "# Import the relevant function\n",
    "None\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_scores should contain 3 scores. If it doesn't, double-check\n",
    "# the value passed in for cv\n",
    "assert len(cv_scores) == 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-599a6362c8ef628f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 4. Compare Baseline and Fitted Model Scores\n",
    "\n",
    "Now, use functions from scikit-learn to compute the accuracy, recall, precision, and f1-score of the fitted model. We have prepared code that will print them out side-by-side with the baseline scores.\n",
    "\n",
    "Documentation can be found [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score), [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score), [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score), and [here](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html#sklearn.metrics.f1_score).\n",
    "\n",
    "This time, **use the test data to calculate each metric.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-264adb30a8921fde",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# CodeGrade step4\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# Replace None with appropriate code\n",
    "y_pred_test = None\n",
    "model_accuracy = None\n",
    "model_recall = None\n",
    "model_precision = None\n",
    "model_f1 = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "Accuracy\n",
    "Baseline: {baseline_accuracy:1.3f} Fitted Model: {model_accuracy:1.3f}\n",
    "Recall\n",
    "Baseline: {baseline_recall:1.3f} Fitted Model: {model_recall:1.3f}\n",
    "Precision\n",
    "Baseline: {baseline_precision:1.3f} Fitted Model: {model_precision:1.3f}\n",
    "F1 Score\n",
    "Baseline: {baseline_f1:1.3f} Fitted Model: {model_f1:1.3f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all scores should be values between 0 and 1\n",
    "assert 0.0 <= model_accuracy and model_accuracy <= 1.0\n",
    "assert 0.0 <= model_recall and model_recall <= 1.0\n",
    "assert 0.0 <= model_precision and model_precision <= 1.0\n",
    "assert 0.0 <= model_f1 and model_f1 <= 1.0"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
